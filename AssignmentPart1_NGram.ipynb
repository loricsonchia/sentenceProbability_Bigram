{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbf6bb83-cf63-4b5d-9cfd-c0635bbd6455",
   "metadata": {},
   "source": [
    "# Unsmoothed and Smoothed Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "303191b2-6086-417f-8b6b-a7f75ae77a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a97a70e-7d22-437b-8b39-49986336c14a",
   "metadata": {},
   "source": [
    "## Defining Training Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7e85748-4f09-4ed6-b365-41e012d187a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training corpus\n",
    "training_corpus = [\n",
    "    \"<s> He read a book </s>\",\n",
    "    \"<s> I read a different book </s>\",\n",
    "    \"<s> He read a book by Danielle </s>\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe26acea-d4e1-42c0-af7d-2d9b0967d81a",
   "metadata": {},
   "source": [
    "## Tokenize Training Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7778e6c1-042d-42ca-a1aa-b0dd8b8481c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the training corpus into words\n",
    "tokenized_corpus = [sentence.split() for sentence in training_corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a375a74-f8cb-469e-8d6d-24e430047ef6",
   "metadata": {},
   "source": [
    "## Unsmoothed Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ac0fb57-22c4-4782-9d44-f98b7981292b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build unsmoothed bigram model\n",
    "unsmoothed_bigram_model = defaultdict(lambda: defaultdict(int))\n",
    "for sentence in tokenized_corpus:\n",
    "    for i in range(len(sentence) - 1):\n",
    "        unsmoothed_bigram_model[sentence[i]][sentence[i+1]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "570b14ba-7341-4f5e-aa1e-7b6f49c6a745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate unsmoothed bigram probabilities\n",
    "unsmoothed_bigram_probabilities = {\n",
    "    word: {next_word: count / sum(next_words.values()) for next_word, count in next_words.items()}\n",
    "    for word, next_words in unsmoothed_bigram_model.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20f12949-8354-43ae-82d2-1598a39264c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sentence probability using unsmoothed bigram model\n",
    "sentence = \"<s> I read a book by Danielle </s>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5af438fe-0e0d-4e93-a159-1c84319ac956",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentence = sentence.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "791c8c58-14f5-46af-9192-a9cce2100a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unsmoothed_probability = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3d5168a-7ca6-42e3-bb63-42fc44dbd703",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tokenized_sentence) - 1):\n",
    "    current_word = tokenized_sentence[i]\n",
    "    next_word = tokenized_sentence[i + 1]\n",
    "    unsmoothed_probability *= unsmoothed_bigram_probabilities[current_word].get(next_word, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014db3cd-5d5e-4ed9-863e-4b8e8497ef80",
   "metadata": {},
   "source": [
    "## Smoothed Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b0255ed-1ef9-49f2-be0b-f92a2028332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build smoothed bigram model using Laplace smoothing\n",
    "V = len(set(word for sentence in tokenized_corpus for word in sentence))  # Vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ebf27a7-1f49-4a71-b5a5-98f388208156",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_bigram_model = defaultdict(lambda: defaultdict(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0d6cef3-e16e-4559-80b9-f22267fbd2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, next_words in unsmoothed_bigram_model.items():\n",
    "    total_count = sum(next_words.values()) + V  # Add V for Laplace smoothing\n",
    "    for next_word in next_words:\n",
    "        smoothed_bigram_model[word][next_word] = (next_words[next_word] + 1) / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54f74efb-f595-449f-95c4-6a38418d2a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sentence probability using smoothed bigram model\n",
    "smoothed_probability = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8659f5c8-6ff6-4d38-89da-a2910a91044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tokenized_sentence) - 1):\n",
    "    current_word = tokenized_sentence[i]\n",
    "    next_word = tokenized_sentence[i + 1]\n",
    "    smoothed_probability *= smoothed_bigram_model[current_word].get(next_word, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35db8e4-322a-4433-910a-d7b10dffed39",
   "metadata": {},
   "source": [
    "## Displaying the Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd869239-a3a8-4851-90c7-90fd305b2a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsmoothed Bigram Model Probability: 0.07407407407407407\n",
      "Smoothed Bigram Model Probability: 1.0101357919757919e-05\n"
     ]
    }
   ],
   "source": [
    "# Print the sentence probabilities\n",
    "print(\"Unsmoothed Bigram Model Probability:\", unsmoothed_probability)\n",
    "print(\"Smoothed Bigram Model Probability:\", smoothed_probability)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
